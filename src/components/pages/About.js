import React from 'react'

export default function About() {
    return (
        <div class="about-section">
            <h1 className='headerAbout'>About this Dashboard</h1>
            <p>For my EECS 605 class, I decided to create a dashboard for NBA sports betting where users can exploit a trained machine learning model to predict the outcome of games. As an avid NBA fan and occasional bettor, I thought it would be interesting to design an all in one website that gives fans a more data driven approach to basketball. To build the website, I used Python to train a machine learning model and do data exploration, AWS to make inferences and update the model, Docker to ship large code packages into AWS, React to design the front end, and Heroku to deploy. By completing this milestone, I was able to enhance my skills in all of these areas and become more comfortable with the entire machine learning pipeline. </p>
            <p>Before training a machine learning model to predict games, I first had to acquire the data. To do this, I used an open source package called nba_api that scrapes nba.com for relevant stats. Stats are accessed via API endpoints, which are called in real time through https GET requests. The functions designated to do this in the nba_api library output data as either a json file, csv, or a Pandas DataFrame, allowing further manipulation of the data after a call. Pandas DataFrames were chosen as the data structure of choice because of its ability to perform quick indexing/grouping operations and compatibility with other scientific computing packages such as NumPy and Scikit-learn. </p>
            <p>Following the acquisition of data, I performed data exploration to confirm some of my own knowledge and decide what is the best way to represent the data for training. I started with the BoxScores API endpoint to get basic box score stats from every game since 2015. I chose 2015 as a starting point because it was the year Stephen Curry won MVP, and is known in basketball circles as the beginning of the 3 point revolution. I plotted the 3 pointers attempted over time, and there was a considerable upward slope justifying that 2015 was a good representation of how the league is today.</p>
            <p>Next, I wanted to see the impact of home court advantage in matchups to determine a baseline for predictions. Home court in basketball is known to have more of an effect than in other sports because role players (those that come off the bench with limited minutes) tend to play better driving the teams overall stats up. I tested this hypothesis by plotting the win percentage of home teams over time, and noticed that the home team consistently wins about 57% of the time. This gave me the idea to predict home team wins in my model to show that a data based approach can yield better insight than a constant, still profitable guess. </p>
            <p>Finally, I wanted to investigate the margin of victory for the away team to determine how close games tend to be. In addition, it is common to see lines for margins of victory so this would be useful to understand in a prediction setting. First, I created a histogram that would represent a coarse, approximate probability distribution. It looked approximately normal, so I tried fitting a normal distribution to it to see if it would be a good approximation of the data set, but it put too much weight on the very close games. Finally, I performed a kernel density estimation to get a distribution that more closely resembles what I would expect. Away teams lose more often than not and usually by 1-10 points with some outliers. </p>
            <p>Based on the information that I learned from data exploration, I decided that the best way to train my model would be to predict the margin of victory of the home team. I made this into a regression problem because the margin of victory simultaneously predicts the winner and how much they are expected to win by (two values that you can bet on). From the home wins plot, I know that to be at least better than a constant guess, I need to get above 57% accuracy. From the KDE plot, I know that a bulk of the probability distribution is around -10 to 10 so I should expect a majority of the margins to land in this range. </p>
            <p>To train the model, I used features from the nba_api endpoint called AdvancedBoxScore. This gives advanced team stats such as offensive efficiency, defensive efficiency, pace of play, pie, etc. The normal counting box score stats were not properly adjusted for a teams competition and had too much variation between games. Following, I dropped any features that had NaN values because there were a couple games that got postponed/canceled so value interpolation was not appropriate. To make learning faster and verify all features were on the same scale, I standardized the data. Finally, I split the data into training and testing and saved the mean and variance of the standardization to use at evaluation time. </p>
            <p>I created a suite of regression models in Scikit-learn to test out which model produces the smallest loss and highest accuracy on test data. The suite included the following methods: Ridge Regression, Random Forest Regressor, Support Vector Regressor w/linear kernel, and Support Vector Regressor w/rbf kernel. All of the models that were tested produced insanely high accuracies (98% or above) on training and testing set, which makes sense because the advanced stats account for both teams performances. The two models that produced the lowest loss were the Support Vector Regressor w/linear kernel and Ridge Regression. I decided to use Ridge Regression as my model of choice because it is the simplest to save and run right out of the box.</p>
            <p>In order to do inference based on this model, I needed to figure out a way to predict the advanced stats that a team would have in an upcoming matchup. I opted to do a moving average to estimate a team's upcoming advanced stats because I did not want to introduce more variance to the margin of victory prediction. I justified this simple time series prediction method by calculating the variance of the following random variable: X = mean(teams last x games) - teams current game. The variance was relatively low for x = 10, so I defaulted on that number. If I had more time, I would have attempted to find a better solution than a simple moving average. </p>
            <p>After training the model, I predicted games every day over 2 weeks with this rolling average set up to get an indication of how my model was actually doing (since the test set wasn't a good indicator). I was able to achieve about ~65% accuracy on the outcome of games, which is a considerable improvement over the baseline ~57% I saw by simply guessing the home team. The margin of victory calculation, as I expected, always predicted somewhere between -10 and 10. </p>
            <p>When investigating the results further, I noticed two things: the model does not predict upsets, and cannot predict blowouts. Because of the simple moving average calculation for the input of the model, the outcome is always predicted based on average performance. There are a lot of confounding variables that contribute to a team's play on a given day, making the performances deviate a lot. There is about a 32% upset rate in the NBA, which is consistent with the fact that the model predicts the correct winner ~65% of the time. In addition, the model typically predicts a margin of victory between -10 - 10 because it is acting on expected performance, and the KDE showed a majority of the distribution was found in this range. All things considered, the NBA is hard to predict and state of the art models show a top end accuracy of ~70%. This means that regardless of better time series approximation, only a marginal improvement can be made.</p>
            <p>After all of the machine learning training was completed, I continued to put the model and code for model inference on AWS lambda. I saved the weights of the chosen model and put it in a folder along with a Dockerfile. AWS lambda limits how much data can be extracted from zip folders of packages/code, so using Docker was the only option for making inferences. In addition, I created front end code in React for the website interface so that users could make predictions with the push of a button. Finally, I posted the code to Github and used the Heroku-Github client to publish the website application on their platform. </p>
            <p>I performed the following steps to do all of the tasks mentioned above:</p>
            <ul className='ul-about'>
                <li>Created an S3 bucket to hold the training data</li>
                <li>Created an EC2 instance in accordance with the EECS 605 module</li>
                <li>Sent the code, saved weights, Dockerfile to the EC2 instance</li>
                <li>Built a Docker image out of the code to set up a virtual machine that had all of the correct packages installed</li>
                <li>Registered the Docker image on AWS ECR </li>
                <li>Created a lambda function that used the docker image registered in the EC2</li>
                <li>Created an API gateway in accordance with EECS 605 module 6 and set it as a trigger for the lambda function</li>
                <li>Modified the front end code of EECS 605 module 7 and hard coded the API url to do a POST request for whenever the predict button was clicked </li>
                <li>Followed the rest of EECS 605 module 7 to get the website hosted on heroku</li>
            </ul>
            <p>To go above and beyond to get an A+ for the class, I decided to make an active learning component to the model. I designed my active learning component such that it would update the data matrix used for predictions every day and the model every two weeks. This was done using an additional lambda function that was triggered on an EventBridge CloudWatch event. Using this trigger, I was able to control the time of day the lambda function gets triggered to ensure that all of the games on a given day were completed before updating. Thus, the website makes predictions based on the most recent game data and with a model that is trained on the most recent data.</p>
            <p>Overall, I was able to execute on all of the goals that I had set out for this project. The assignment was tough considering all of the moving parts in the pipeline, but it was both a fun and informative experience. In future iterations of the project, I would want to add more visuals to the website so that users dont have to look at stats on other web pages in addition to mine. Below are pictures of the models succeeding and failing, as well as the active learning component working</p>
            <p>I took inspiration from <a href="https://klane.github.io/databall/">Databall</a> for my data exploration phase (recreated graphs with nba_api data), and referenced course materials for AWS support</p>
            <p>Happy Betting! -Elijah</p>

        </div>
    );
}

